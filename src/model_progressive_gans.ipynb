{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "art_generator.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQ6HpDJkelz",
        "colab_type": "text"
      },
      "source": [
        "# Progressive GANS \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYSbED0xRbHb",
        "colab_type": "text"
      },
      "source": [
        "This is a Progressive GANS model inspired by https://research.nvidia.com/publication/2017-10_Progressive-Growing-of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb6NFch4kelz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivag9g9soyQ1",
        "colab_type": "code",
        "outputId": "5d71fa85-0b1c-4dcd-b6c5-95fe8385d6ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mounts the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-xs0kl5kel3",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXtmNIKekel3",
        "colab_type": "code",
        "outputId": "d72ae438-c282-41af-e816-35da685161de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# images\n",
        "PARENT_DIR = '/content/drive/My Drive/repos/art_generator/'\n",
        "IMG_DIR = PARENT_DIR + 'data_raw/all/'\n",
        "IMG_SIZE = 16\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# graph\n",
        "GEN_INPUT_SIZE = 100\n",
        "N_LAYERS = int(np.log(IMG_SIZE) / np.log(2)) - 1\n",
        "N_GEN_CHANNELS = 64\n",
        "N_DISC_CHANNELS = 64\n",
        "beta1 = 0.5\n",
        "\n",
        "# training\n",
        "N_EPOCHS = 1000\n",
        "LR = 0.0002\n",
        "N_WORKERS = 2\n",
        "BATCH_SIZE = 16\n",
        "ngpu = 1\n",
        "\n",
        "# checkpoints and logs\n",
        "CHECKPOINT_TYPE = 'none' # prev_model will load the previous model, prev_checkpoint will load the last checkpoint, none will do none. \n",
        "LOGDIR = PARENT_DIR + 'data_out/logs/size-' + str(IMG_SIZE) + '/'\n",
        "\n",
        "print('Number of layers: ' + str(N_LAYERS))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SswUiXZHkel6",
        "colab_type": "text"
      },
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoeqelJXddYO",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxK-miokdx8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3d387c9-1ed0-422c-97f4-d9ccc0085e18"
      },
      "source": [
        "# gets the list of images that are equal to or larger than our image output size \n",
        "img_list = glob.glob(IMG_DIR + '*')\n",
        "print('Number of all images: %d' % len(img_list))\n",
        "img_list = [img for img in img_list if min(Image.open(img).size) >= IMG_SIZE]\n",
        "print('Number of images in size range: %d' % len(img_list))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of all images: 306\n",
            "Number of images in size range: 306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirJKQqpefrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a custom dataset class for reading in our images from the list\n",
        "class ReadFromList(Dataset):\n",
        "\n",
        "    def __init__(self, img_list, transform=None):\n",
        "        self.samples = img_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.samples[idx])\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqmLVtA3T5TX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b123bdbd-b70e-407a-e441-e472e4b93eed"
      },
      "source": [
        "# makes the dataset and data loader\n",
        "dataset = ReadFromList(img_list, transform=transforms.Compose([\n",
        "                                    transforms.Resize(IMG_SIZE),\n",
        "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                    transforms.RandomVerticalFlip(p=0.5),\n",
        "                                    transforms.CenterCrop(IMG_SIZE),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
        "                        )\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "print('Size of dataset: %d' % len(dataloader.dataset.samples))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of dataset: 306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIWBjy8Wf4uK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "1a1f25c9-96ae-494d-b40b-f85139849516"
      },
      "source": [
        "for i, data in enumerate(dataloader, 0):\n",
        "    print(i)\n",
        "    break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-37cb26d19bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-5-08b47b416009>\", line 14, in __getitem__\n    image = self.transform(image)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 166, in __call__\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 208, in normalize\n    tensor.sub_(mean).div_(std)\nRuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcILz4ye6h2",
        "colab_type": "text"
      },
      "source": [
        "### Cuda Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tOFSMIukel9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK1yExWpe05q",
        "colab_type": "text"
      },
      "source": [
        "### Image Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjETDy6Rkel_",
        "colab_type": "code",
        "outputId": "302eaea8-b838-4d5a-cc44-f2377f6df5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        }
      },
      "source": [
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True, nrow=4).cpu(),(1,2,0)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f47558c1a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZJPG0G8fG9i",
        "colab_type": "text"
      },
      "source": [
        "### Sets Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayq_2-OOkemC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0mPh4Q2kemE",
        "colab_type": "text"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64hmVh4kemF",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6sXkZy7kemF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, n_layers):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.ConvTranspose2d(GEN_INPUT_SIZE, N_GEN_CHANNELS * 2, 4, 1, 0, bias=False)])\n",
        "        self.layers.extend([nn.ConvTranspose2d(N_GEN_CHANNELS * 2, N_GEN_CHANNELS * 2, 4, 2, 1, bias=False) for i in range(self.n_layers - 3)])\n",
        "        self.layers.extend([nn.ConvTranspose2d(N_GEN_CHANNELS * 2, N_GEN_CHANNELS, 4, 2, 1, bias=False),\n",
        "                            nn.ConvTranspose2d(N_GEN_CHANNELS, N_CHANNELS, 4, 2, 1, bias=False)])                   \n",
        "                           \n",
        "        self.batch1 = nn.BatchNorm2d(N_GEN_CHANNELS)\n",
        "        self.batch2 = nn.BatchNorm2d(N_GEN_CHANNELS * 2)\n",
        "\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, name in enumerate(self.layers):\n",
        "            x = self.layers[i](x)\n",
        "\n",
        "            if self.layers[i].out_channels == N_GEN_CHANNELS * 2:\n",
        "                x = self.batch2(x)\n",
        "                x = self.relu(x)\n",
        "            elif self.layers[i].out_channels == N_GEN_CHANNELS:\n",
        "                x = self.batch1(x)\n",
        "                x = self.relu(x)\n",
        "            else:\n",
        "                x = self.tanh(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi8ZQ97gkemI",
        "colab_type": "code",
        "outputId": "7dba5285-8d7f-49d2-84b4-73a09f2556dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu, N_LAYERS).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netG.apply(weights_init)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (layers): ModuleList(\n",
              "    (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (2): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (batch1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batch2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (tanh): Tanh()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKRiaEWPkemK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu, n_layers):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.Conv2d(N_CHANNELS, N_DISC_CHANNELS * 2, 4, 2, 1, bias=False)])\n",
        "        self.layers.extend([nn.Conv2d(N_DISC_CHANNELS * 2, N_DISC_CHANNELS * 2, 4, 2, 1, bias=False) for i in range(self.n_layers - 2)])\n",
        "        self.layers.append(nn.Conv2d(N_DISC_CHANNELS * 2, 1, 4, 1, 0, bias=False))\n",
        "                           \n",
        "        self.batch2 = nn.BatchNorm2d(N_DISC_CHANNELS * 2)\n",
        "\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        for i, name in enumerate(self.layers):\n",
        "            x = self.layers[i](x)\n",
        "\n",
        "            if i == 0:\n",
        "                x = self.LeakyReLU(x)            \n",
        "            elif self.layers[i].out_channels == N_DISC_CHANNELS * 2:\n",
        "                x = self.batch2(x)\n",
        "                x = self.LeakyReLU(x)\n",
        "            else:\n",
        "                x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9fOj2jHkemM",
        "colab_type": "code",
        "outputId": "4e61fa1f-9174-4cf5-82a8-48da4f3f6518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu, N_LAYERS).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (layers): ModuleList(\n",
              "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (2): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (batch2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmobenkbkemQ",
        "colab_type": "text"
      },
      "source": [
        "### Loss Functions and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLMIkppNkemQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(beta1, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZeI-7TkkemS",
        "colab_type": "text"
      },
      "source": [
        "### Loads Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQRf3QHbM1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if CHECKPOINT_TYPE == 'prev_model':\n",
        "    prev_model_path = DATA_DIR + '/art_generator/data_out/logs/size-' + str(int(IMG_SIZE / 2)) + '/checkpoint.pt' \n",
        "    checkpoint = torch.load(prev_model_path)\n",
        "\n",
        "    # applies the weights to the needed layers\n",
        "    for layer in range(N_LAYERS - 3):\n",
        "        netG.state_dict()['layers.' + str(layer) + '.weight'] = checkpoint['netG_state']['layers.' + str(layer) + '.weight']\n",
        "\n",
        "    # freezes the layers\n",
        "    for i, param in enumerate(netG.parameters()):\n",
        "        if i < N_LAYERS - 3:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # resets the optimizer with the new parameter values\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(beta1, 0.999))\n",
        "\n",
        "    epoch_counter = 1\n",
        "\n",
        "elif CHECKPOINT_TYPE == 'prev_checkpoint':\n",
        "    # loads the model weights\n",
        "    checkpoint = torch.load(LOGDIR + 'checkpoint.pt')\n",
        "    netG.load_state_dict(checkpoint['netG_state'])\n",
        "    optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
        "    netD.load_state_dict(checkpoint['netD_state'])\n",
        "    optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
        "    print('Checkpoint Loaded')\n",
        "    \n",
        "    # loads the epoch counter\n",
        "    with open(LOGDIR + 'itercount.txt', 'r') as f:\n",
        "        epoch_counter = int(f.read())\n",
        "    # moves it up one becuase it's currenlty at the last epoch we did\n",
        "    epoch_counter += 1\n",
        "\n",
        "elif CHECKPOINT_TYPE == 'none':\n",
        "    # remove all previous logs\n",
        "    try:\n",
        "        shutil.rmtree(LOGDIR)\n",
        "    except FileNotFoundError:\n",
        "        print('No log folder found')\n",
        "\n",
        "    epoch_counter = 1\n",
        "else:\n",
        "    print('Failed to specify a type')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXv7nj8SkemV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jqlD8b4kemV",
        "colab_type": "code",
        "outputId": "8b24731e-f36d-4743-e6a3-3599bb2fd325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "# Training Loop\n",
        "writer = SummaryWriter(LOGDIR)\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(N_EPOCHS):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        \n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device)\n",
        "\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "    # Save the loss for the generator and discriminator\n",
        "    writer.add_scalar('Loss/Gen', errG.item(), epoch_counter)\n",
        "    writer.add_scalar('Loss/Disc', errD.item(), epoch_counter)\n",
        "\n",
        "    # print the status\n",
        "    print('EPOCH: [%d/%d] BATCH: [%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "            % (epoch_counter, N_EPOCHS, i, len(dataloader),\n",
        "                errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "    \n",
        "    # saves a checkpoint        \n",
        "    checkpoint = {'netG_state': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
        "                    'netD_state': netD.state_dict(), 'optimizerD': optimizerD.state_dict()}\n",
        "    torch.save(checkpoint, LOGDIR + 'checkpoint.pt')\n",
        "    \n",
        "    # saves the epoch counter\n",
        "    with open(LOGDIR + '/itercount.txt', 'w') as f:\n",
        "        f.write(str(epoch_counter))\n",
        "\n",
        "    # Saves an image so we can view the progression\n",
        "    with torch.no_grad():\n",
        "        output = netG(fixed_noise).detach().cpu()\n",
        "    grid = torchvision.utils.make_grid(output[8])\n",
        "    writer.add_image('image_epoch_' + str(epoch_counter), grid)\n",
        "\n",
        "    # increments our counter\n",
        "    epoch_counter += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d713d725fb44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# For each batch in the dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-5-08b47b416009>\", line 14, in __getitem__\n    image = self.transform(image)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 166, in __call__\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 208, in normalize\n    tensor.sub_(mean).div_(std)\nRuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4RRxrETkemZ",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyJNGS4Ikeme",
        "colab_type": "text"
      },
      "source": [
        "### Batch of Real and Fake Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTdq7hARkeme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# makes the image list\n",
        "with torch.no_grad():\n",
        "    fake = netG(fixed_noise).detach().cpu()\n",
        "img_list.append(vutils.make_grid(fake[:16], padding=2, normalize=True, nrow=4))\n",
        "\n",
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:16], padding=2, normalize=True, nrow=4).cpu(),(1, 2, 0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaVgB6vAkemg",
        "colab_type": "text"
      },
      "source": [
        "### Random Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pdFQKFYkemg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for converting images to a normal range\n",
        "def img_scale(img_tensor):\n",
        "    min_value = img_tensor.min()\n",
        "    span = img_tensor.max() - img_tensor.min()\n",
        "    img_tensor = (img_tensor - min_value) / span\n",
        "    img_tensor = np.transpose(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "output = netG(noise).detach().cpu()\n",
        "plt.imshow(img_scale(output[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "art_generator.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/art_generator/blob/master/src/model_progressive_gans_art_006.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQ6HpDJkelz",
        "colab_type": "text"
      },
      "source": [
        "# Progressive GANS Img Size 256 Previous Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLyUC_nBJ_hn",
        "colab_type": "text"
      },
      "source": [
        "**Test**\n",
        "\n",
        "Image size 256.\n",
        "Progressed from previous model\n",
        "\n",
        "**Results**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYSbED0xRbHb",
        "colab_type": "text"
      },
      "source": [
        "This is a Progressive GANS model inspired by https://research.nvidia.com/publication/2017-10_Progressive-Growing-of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb6NFch4kelz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivag9g9soyQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3b39935e-22d1-477f-af94-c5a949a7f5c9"
      },
      "source": [
        "# mounts the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-xs0kl5kel3",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXtmNIKekel3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4bef7f7-c19c-41a4-ceeb-e5866d0d459e"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# images\n",
        "PARENT_DIR = '/content/drive/My Drive/repos/art_generator/'\n",
        "IMG_DIR = PARENT_DIR + 'data_raw/art/all/'\n",
        "IMG_SIZE = 256\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# graph\n",
        "GEN_INPUT_SIZE = 100\n",
        "N_LAYERS = int(np.log(IMG_SIZE) / np.log(2)) - 1\n",
        "N_GEN_CHANNELS = 128\n",
        "N_DISC_CHANNELS = 128\n",
        "beta1 = 0.5\n",
        "\n",
        "# training\n",
        "N_EPOCHS = 192\n",
        "LR = 0.0002\n",
        "N_WORKERS = 2\n",
        "BATCH_SIZE = 16\n",
        "ngpu = 1\n",
        "\n",
        "# checkpoints and logs\n",
        "CHECKPOINT_TYPE = 'prev_checkpoint' # prev_model will load the previous model, prev_checkpoint will load the last checkpoint, none will do none. \n",
        "LOGDIR = PARENT_DIR + 'data_out/logs/size-' + str(IMG_SIZE) + '/'\n",
        "\n",
        "print('Number of layers: ' + str(N_LAYERS))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SswUiXZHkel6",
        "colab_type": "text"
      },
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoeqelJXddYO",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxK-miokdx8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a3941f0-197f-4a44-c074-320d667066c6"
      },
      "source": [
        "# gets the list of images that are equal to or larger than our image output size \n",
        "img_list = glob.glob(IMG_DIR + '*')\n",
        "print('Number of all images: %d' % len(img_list))\n",
        "img_list = [img for img in img_list if min(Image.open(img).size) >= IMG_SIZE]\n",
        "print('Number of images in size range: %d' % len(img_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of all images: 1763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirJKQqpefrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a custom dataset class for reading in our images from the list\n",
        "class ReadFromList(Dataset):\n",
        "\n",
        "    def __init__(self, img_list, transform=None):\n",
        "        self.samples = img_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.samples[idx]).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqmLVtA3T5TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# makes the dataset and data loader\n",
        "dataset = ReadFromList(img_list, transform=transforms.Compose([\n",
        "                                    transforms.Resize(IMG_SIZE),\n",
        "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                    transforms.RandomVerticalFlip(p=0.5),\n",
        "                                    transforms.CenterCrop(IMG_SIZE),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
        "                        )\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "print('Size of dataset: %d' % len(dataloader.dataset.samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcILz4ye6h2",
        "colab_type": "text"
      },
      "source": [
        "### Cuda Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tOFSMIukel9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK1yExWpe05q",
        "colab_type": "text"
      },
      "source": [
        "### Image Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjETDy6Rkel_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True, nrow=4).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZJPG0G8fG9i",
        "colab_type": "text"
      },
      "source": [
        "### Sets Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayq_2-OOkemC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0mPh4Q2kemE",
        "colab_type": "text"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64hmVh4kemF",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6sXkZy7kemF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, n_layers):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.ConvTranspose2d(GEN_INPUT_SIZE, N_GEN_CHANNELS * 2, 4, 1, 0, bias=False)])\n",
        "        self.layers.extend([nn.ConvTranspose2d(N_GEN_CHANNELS * 2, N_GEN_CHANNELS * 2, 4, 2, 1, bias=False) for i in range(self.n_layers - 3)])\n",
        "        self.layers.extend([nn.ConvTranspose2d(N_GEN_CHANNELS * 2, N_GEN_CHANNELS, 4, 2, 1, bias=False),\n",
        "                            nn.ConvTranspose2d(N_GEN_CHANNELS, N_CHANNELS, 4, 2, 1, bias=False)])                   \n",
        "                           \n",
        "        self.batch1 = nn.BatchNorm2d(N_GEN_CHANNELS)\n",
        "        self.batch2 = nn.BatchNorm2d(N_GEN_CHANNELS * 2)\n",
        "\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, name in enumerate(self.layers):\n",
        "            x = self.layers[i](x)\n",
        "\n",
        "            if self.layers[i].out_channels == N_GEN_CHANNELS * 2:\n",
        "                x = self.batch2(x)\n",
        "                x = self.relu(x)\n",
        "            elif self.layers[i].out_channels == N_GEN_CHANNELS:\n",
        "                x = self.batch1(x)\n",
        "                x = self.relu(x)\n",
        "            else:\n",
        "                x = self.tanh(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi8ZQ97gkemI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu, N_LAYERS).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netG.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKRiaEWPkemK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu, n_layers):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.Conv2d(N_CHANNELS, N_DISC_CHANNELS * 2, 4, 2, 1, bias=False)])\n",
        "        self.layers.extend([nn.Conv2d(N_DISC_CHANNELS * 2, N_DISC_CHANNELS * 2, 4, 2, 1, bias=False) for i in range(self.n_layers - 2)])\n",
        "        self.layers.append(nn.Conv2d(N_DISC_CHANNELS * 2, 1, 4, 1, 0, bias=False))\n",
        "                           \n",
        "        self.batch2 = nn.BatchNorm2d(N_DISC_CHANNELS * 2)\n",
        "\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        for i, name in enumerate(self.layers):\n",
        "            x = self.layers[i](x)\n",
        "\n",
        "            if i == 0:\n",
        "                x = self.LeakyReLU(x)            \n",
        "            elif self.layers[i].out_channels == N_DISC_CHANNELS * 2:\n",
        "                x = self.batch2(x)\n",
        "                x = self.LeakyReLU(x)\n",
        "            else:\n",
        "                x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9fOj2jHkemM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu, N_LAYERS).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmobenkbkemQ",
        "colab_type": "text"
      },
      "source": [
        "### Loss Functions and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLMIkppNkemQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(beta1, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZeI-7TkkemS",
        "colab_type": "text"
      },
      "source": [
        "### Loads Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQRf3QHbM1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if CHECKPOINT_TYPE == 'prev_model':\n",
        "    prev_model_path = PARENT_DIR + 'data_out/logs/size-' + str(int(IMG_SIZE / 2)) + '/checkpoint.pt'\n",
        "    checkpoint = torch.load(prev_model_path)\n",
        "\n",
        "    # Generator 1, x, 2\n",
        "    # applies the weights to the needed layers\n",
        "    for layer in range(N_LAYERS - 3):\n",
        "        netG.state_dict()['layers.' + str(layer) + '.weight'] = checkpoint['netG_state']['layers.' + str(layer) + '.weight']\n",
        "\n",
        "    # # freezes the layers\n",
        "    # for i, param in enumerate(netG.parameters()):\n",
        "    #     if i < N_LAYERS - 3:\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    # resets the optimizer with the new parameter values\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(beta1, 0.999))\n",
        "\n",
        "    # Discriminator 1, x, 1\n",
        "    for layer in range(N_LAYERS - 2):\n",
        "        netD.state_dict()['layers.' + str(layer) + '.weight'] = checkpoint['netD_state']['layers.' + str(layer) + '.weight']\n",
        "\n",
        "    # # freezes the layers\n",
        "    # for i, param in enumerate(netD.parameters()):\n",
        "    #     if i < N_LAYERS - 2:\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "\n",
        "    epoch_counter = 1\n",
        "\n",
        "elif CHECKPOINT_TYPE == 'prev_checkpoint':\n",
        "    # loads the model weights\n",
        "    checkpoint = torch.load(LOGDIR + 'checkpoint.pt')\n",
        "    netG.load_state_dict(checkpoint['netG_state'])\n",
        "    optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
        "    netD.load_state_dict(checkpoint['netD_state'])\n",
        "    optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
        "    print('Checkpoint Loaded')\n",
        "    \n",
        "    # loads the epoch counter\n",
        "    with open(LOGDIR + 'itercount.txt', 'r') as f:\n",
        "        epoch_counter = int(f.read())\n",
        "    # moves it up one becuase it's currenlty at the last epoch we did\n",
        "    epoch_counter += 1\n",
        "\n",
        "elif CHECKPOINT_TYPE == 'none':\n",
        "    # remove all previous logs\n",
        "    try:\n",
        "        shutil.rmtree(LOGDIR)\n",
        "    except FileNotFoundError:\n",
        "        print('No log folder found')\n",
        "\n",
        "    epoch_counter = 1\n",
        "else:\n",
        "    print('Failed to specify a type')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXv7nj8SkemV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jqlD8b4kemV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Loop\n",
        "writer = SummaryWriter(LOGDIR)\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(N_EPOCHS):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        \n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device)\n",
        "\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "    # Save the loss for the generator and discriminator\n",
        "    writer.add_scalar('Loss/Gen', errG.item(), epoch_counter)\n",
        "    writer.add_scalar('Loss/Disc', errD.item(), epoch_counter)\n",
        "\n",
        "    # print the status\n",
        "    print('EPOCH: [%d/%d] BATCH: [%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "            % (epoch_counter, N_EPOCHS, i, len(dataloader),\n",
        "                errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "    \n",
        "    # saves a checkpoint        \n",
        "    checkpoint = {'netG_state': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
        "                    'netD_state': netD.state_dict(), 'optimizerD': optimizerD.state_dict()}\n",
        "    torch.save(checkpoint, LOGDIR + 'checkpoint.pt')\n",
        "    \n",
        "    # saves the epoch counter\n",
        "    with open(LOGDIR + '/itercount.txt', 'w') as f:\n",
        "        f.write(str(epoch_counter))\n",
        "\n",
        "    # Saves an image so we can view the progression\n",
        "    with torch.no_grad():\n",
        "        output = netG(fixed_noise).detach().cpu()\n",
        "    grid = torchvision.utils.make_grid(output[8])\n",
        "    writer.add_image('image_epoch_' + str(epoch_counter), grid)\n",
        "\n",
        "    # increments our counter\n",
        "    epoch_counter += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4RRxrETkemZ",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyJNGS4Ikeme",
        "colab_type": "text"
      },
      "source": [
        "### Batch of Real and Fake Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTdq7hARkeme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# makes the image list\n",
        "with torch.no_grad():\n",
        "    fake = netG(fixed_noise).detach().cpu()\n",
        "img_list.append(vutils.make_grid(fake[:16], padding=2, normalize=True, nrow=4))\n",
        "\n",
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:16], padding=2, normalize=True, nrow=4).cpu(),(1, 2, 0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaVgB6vAkemg",
        "colab_type": "text"
      },
      "source": [
        "### Random Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pdFQKFYkemg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for converting images to a normal range\n",
        "def img_scale(img_tensor):\n",
        "    min_value = img_tensor.min()\n",
        "    span = img_tensor.max() - img_tensor.min()\n",
        "    img_tensor = (img_tensor - min_value) / span\n",
        "    img_tensor = np.transpose(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "output = netG(noise).detach().cpu()\n",
        "plt.imshow(img_scale(output[0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
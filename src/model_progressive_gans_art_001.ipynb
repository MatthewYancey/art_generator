{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "art_generator.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/art_generator/blob/master/src/model_progressive_gans_art_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQ6HpDJkelz",
        "colab_type": "text"
      },
      "source": [
        "# Progressive GANS Img Size 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLyUC_nBJ_hn",
        "colab_type": "text"
      },
      "source": [
        "**Test**\n",
        "\n",
        "Image size 32.\n",
        "No previous model\n",
        "\n",
        "**Results**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYSbED0xRbHb",
        "colab_type": "text"
      },
      "source": [
        "This is a Progressive GANS model inspired by https://research.nvidia.com/publication/2017-10_Progressive-Growing-of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb6NFch4kelz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivag9g9soyQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "cee0cf9e-4e40-4e6a-c1c1-b7ab81ec20a5"
      },
      "source": [
        "# mounts the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2f92e92f83df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mounts the google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-xs0kl5kel3",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXtmNIKekel3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# images\n",
        "PARENT_DIR = '/content/drive/My Drive/repos/art_generator/'\n",
        "IMG_DIR = PARENT_DIR + 'data_raw/art/all/'\n",
        "IMG_SIZE = 32\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# graph\n",
        "GEN_INPUT_SIZE = 100\n",
        "N_LAYERS = int(np.log(IMG_SIZE) / np.log(2)) - 1\n",
        "N_GEN_CHANNELS = 128\n",
        "N_DISC_CHANNELS = 128\n",
        "beta1 = 0.5\n",
        "\n",
        "# training\n",
        "N_EPOCHS = 32\n",
        "LR = 0.0002\n",
        "N_WORKERS = 2\n",
        "BATCH_SIZE = 16\n",
        "ngpu = 1\n",
        "\n",
        "# checkpoints and logs\n",
        "CHECKPOINT_TYPE = 'prev_checkpoint' # prev_model will load the previous model, prev_checkpoint will load the last checkpoint, none will do none. \n",
        "LOGDIR = PARENT_DIR + 'data_out/logs/size-' + str(IMG_SIZE) + '/'\n",
        "\n",
        "print('Number of layers: ' + str(N_LAYERS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOhIaNqEz1xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for converting images to a normal range\n",
        "def img_scale(img_tensor, grid=True):\n",
        "    min_value = img_tensor.min()\n",
        "    span = img_tensor.max() - img_tensor.min()\n",
        "    img_tensor = (img_tensor - min_value) / span\n",
        "\n",
        "    if grid is False:\n",
        "        img_tensor = np.transpose(img_tensor)\n",
        "\n",
        "    return img_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SswUiXZHkel6",
        "colab_type": "text"
      },
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoeqelJXddYO",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxK-miokdx8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gets the list of images that are equal to or larger than our image output size \n",
        "img_list = glob.glob(IMG_DIR + '*')\n",
        "print('Number of all images: %d' % len(img_list))\n",
        "img_list = [img for img in img_list if min(Image.open(img).size) >= IMG_SIZE]\n",
        "print('Number of images in size range: %d' % len(img_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirJKQqpefrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a custom dataset class for reading in our images from the list\n",
        "class ReadFromList(Dataset):\n",
        "\n",
        "    def __init__(self, img_list, transform=None):\n",
        "        self.samples = img_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.samples[idx]).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqmLVtA3T5TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# makes the dataset and data loader\n",
        "dataset = ReadFromList(img_list, transform=transforms.Compose([\n",
        "                                    transforms.Resize(IMG_SIZE),\n",
        "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                    transforms.RandomVerticalFlip(p=0.5),\n",
        "                                    transforms.CenterCrop(IMG_SIZE),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
        "                        )\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "print('Size of dataset: %d' % len(dataloader.dataset.samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcILz4ye6h2",
        "colab_type": "text"
      },
      "source": [
        "### Cuda Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tOFSMIukel9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK1yExWpe05q",
        "colab_type": "text"
      },
      "source": [
        "### Image Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjETDy6Rkel_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True, nrow=4).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZJPG0G8fG9i",
        "colab_type": "text"
      },
      "source": [
        "### Sets Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayq_2-OOkemC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0mPh4Q2kemE",
        "colab_type": "text"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64hmVh4kemF",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6sXkZy7kemF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, n_layers):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.ConvTranspose2d(GEN_INPUT_SIZE, N_GEN_CHANNELS * 2, 4, 1, 0, bias=False)])\n",
        "        self.layers.extend([nn.ConvTranspose2d(N_GEN_CHANNELS * 2, N_GEN_CHANNELS * 2, 4, 2, 1, bias=False) for i in range(self.n_layers - 3)])\n",
        "        self.layers.extend([nn.ConvTranspose2d(N_GEN_CHANNELS * 2, N_GEN_CHANNELS, 4, 2, 1, bias=False),\n",
        "                            nn.ConvTranspose2d(N_GEN_CHANNELS, N_CHANNELS, 4, 2, 1, bias=False)])                   \n",
        "                           \n",
        "        self.batch1 = nn.BatchNorm2d(N_GEN_CHANNELS)\n",
        "        self.batch2 = nn.BatchNorm2d(N_GEN_CHANNELS * 2)\n",
        "\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, name in enumerate(self.layers):\n",
        "            x = self.layers[i](x)\n",
        "\n",
        "            if self.layers[i].out_channels == N_GEN_CHANNELS * 2:\n",
        "                x = self.batch2(x)\n",
        "                x = self.relu(x)\n",
        "            elif self.layers[i].out_channels == N_GEN_CHANNELS:\n",
        "                x = self.batch1(x)\n",
        "                x = self.relu(x)\n",
        "            else:\n",
        "                x = self.tanh(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi8ZQ97gkemI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu, N_LAYERS).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netG.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKRiaEWPkemK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu, n_layers):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.Conv2d(N_CHANNELS, N_DISC_CHANNELS * 2, 4, 2, 1, bias=False)])\n",
        "        self.layers.extend([nn.Conv2d(N_DISC_CHANNELS * 2, N_DISC_CHANNELS * 2, 4, 2, 1, bias=False) for i in range(self.n_layers - 2)])\n",
        "        self.layers.append(nn.Conv2d(N_DISC_CHANNELS * 2, 1, 4, 1, 0, bias=False))\n",
        "                           \n",
        "        self.batch2 = nn.BatchNorm2d(N_DISC_CHANNELS * 2)\n",
        "\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        for i, name in enumerate(self.layers):\n",
        "            x = self.layers[i](x)\n",
        "\n",
        "            if i == 0:\n",
        "                x = self.LeakyReLU(x)            \n",
        "            elif self.layers[i].out_channels == N_DISC_CHANNELS * 2:\n",
        "                x = self.batch2(x)\n",
        "                x = self.LeakyReLU(x)\n",
        "            else:\n",
        "                x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9fOj2jHkemM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu, N_LAYERS).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmobenkbkemQ",
        "colab_type": "text"
      },
      "source": [
        "### Loss Functions and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLMIkppNkemQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(beta1, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZeI-7TkkemS",
        "colab_type": "text"
      },
      "source": [
        "### Loads Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQRf3QHbM1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if CHECKPOINT_TYPE == 'prev_model':\n",
        "    prev_model_path = PARENT_DIR + 'data_out/logs/size-' + str(int(IMG_SIZE / 2)) + '/checkpoint.pt'\n",
        "    checkpoint = torch.load(prev_model_path)\n",
        "\n",
        "    # Generator 1, x, 2\n",
        "    # applies the weights to the needed layers\n",
        "    for layer in range(N_LAYERS - 3):\n",
        "        netG.state_dict()['layers.' + str(layer) + '.weight'] = checkpoint['netG_state']['layers.' + str(layer) + '.weight']\n",
        "\n",
        "    # # freezes the layers\n",
        "    # for i, param in enumerate(netG.parameters()):\n",
        "    #     if i < N_LAYERS - 3:\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    # resets the optimizer with the new parameter values\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(beta1, 0.999))\n",
        "\n",
        "    # Discriminator 1, x, 1\n",
        "    for layer in range(N_LAYERS - 2):\n",
        "        netD.state_dict()['layers.' + str(layer) + '.weight'] = checkpoint['netD_state']['layers.' + str(layer) + '.weight']\n",
        "\n",
        "    # # freezes the layers\n",
        "    # for i, param in enumerate(netD.parameters()):\n",
        "    #     if i < N_LAYERS - 2:\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "\n",
        "    epoch_counter = 1\n",
        "\n",
        "elif CHECKPOINT_TYPE == 'prev_checkpoint':\n",
        "    # loads the model weights\n",
        "    checkpoint = torch.load(LOGDIR + 'checkpoint.pt')\n",
        "    netG.load_state_dict(checkpoint['netG_state'])\n",
        "    optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
        "    netD.load_state_dict(checkpoint['netD_state'])\n",
        "    optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
        "    print('Checkpoint Loaded')\n",
        "    \n",
        "    # loads the epoch counter\n",
        "    with open(LOGDIR + 'itercount.txt', 'r') as f:\n",
        "        epoch_counter = int(f.read())\n",
        "    # moves it up one becuase it's currenlty at the last epoch we did\n",
        "    epoch_counter += 1\n",
        "\n",
        "elif CHECKPOINT_TYPE == 'none':\n",
        "    # remove all previous logs\n",
        "    try:\n",
        "        shutil.rmtree(LOGDIR)\n",
        "        print('Folders removed')\n",
        "    except FileNotFoundError:\n",
        "        print('No log folder found')\n",
        "\n",
        "    epoch_counter = 1\n",
        "else:\n",
        "    print('Failed to specify a type')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXv7nj8SkemV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jqlD8b4kemV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Loop\n",
        "writer = SummaryWriter(LOGDIR)\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(N_EPOCHS):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        \n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device)\n",
        "\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "    # Save the loss for the generator and discriminator\n",
        "    writer.add_scalar('Loss/Gen', errG.item(), epoch_counter)\n",
        "    writer.add_scalar('Loss/Disc', errD.item(), epoch_counter)\n",
        "\n",
        "    # print the status\n",
        "    print('EPOCH: [%d/%d] BATCH: [%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "            % (epoch_counter, N_EPOCHS, i, len(dataloader),\n",
        "                errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "    \n",
        "    # saves a checkpoint        \n",
        "    checkpoint = {'netG_state': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
        "                    'netD_state': netD.state_dict(), 'optimizerD': optimizerD.state_dict()}\n",
        "    torch.save(checkpoint, LOGDIR + 'checkpoint.pt')\n",
        "    \n",
        "    # saves the epoch counter\n",
        "    with open(LOGDIR + '/itercount.txt', 'w') as f:\n",
        "        f.write(str(epoch_counter))\n",
        "\n",
        "    # Saves an image so we can view the progression\n",
        "    with torch.no_grad():\n",
        "        output = netG(fixed_noise).detach().cpu()\n",
        "    grid = torchvision.utils.make_grid(output[8])\n",
        "    writer.add_image('image_epoch_' + str(epoch_counter), img_scale(grid))\n",
        "\n",
        "    # increments our counter\n",
        "    epoch_counter += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33OOJmOu1rKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Saves an image so we can view the progression\n",
        "# with torch.no_grad():\n",
        "#     output = netG(fixed_noise).detach().cpu()\n",
        "# grid = torchvision.utils.make_grid(output[8])\n",
        "# writer.add_image('image_epoch_' + str(epoch_counter), img_scale(grid))\n",
        "\n",
        "# noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "# output = netG(noise).detach().cpu()\n",
        "# output[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4RRxrETkemZ",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyJNGS4Ikeme",
        "colab_type": "text"
      },
      "source": [
        "### Batch of Real and Fake Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTdq7hARkeme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# makes the image list\n",
        "with torch.no_grad():\n",
        "    fake = netG(fixed_noise).detach().cpu()\n",
        "img_list.append(vutils.make_grid(fake[:16], padding=2, normalize=True, nrow=4))\n",
        "\n",
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:16], padding=2, normalize=True, nrow=4).cpu(),(1, 2, 0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaVgB6vAkemg",
        "colab_type": "text"
      },
      "source": [
        "### Random Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pdFQKFYkemg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for converting images to a normal range\n",
        "def img_scale(img_tensor):\n",
        "    min_value = img_tensor.min()\n",
        "    span = img_tensor.max() - img_tensor.min()\n",
        "    img_tensor = (img_tensor - min_value) / span\n",
        "    img_tensor = np.transpose(img_tensor)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "noise = torch.randn(b_size, GEN_INPUT_SIZE, 1, 1, device=device)\n",
        "output = netG(noise).detach().cpu()\n",
        "plt.imshow(img_scale(output[0], grid=False))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}